{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webnlg_human_evaluation_russian.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqODNsrNmNBc",
        "outputId": "6b36b0f8-8fcf-4247-f1da-c3db88b14046"
      },
      "source": [
        "!git clone https://github.com/WebNLG/GenerationEval.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GenerationEval'...\n",
            "remote: Enumerating objects: 198, done.\u001b[K\n",
            "remote: Counting objects: 100% (198/198), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 198 (delta 112), reused 168 (delta 88), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (198/198), 1.49 MiB | 14.14 MiB/s, done.\n",
            "Resolving deltas: 100% (112/112), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA98wK1GmxjF"
      },
      "source": [
        "import os\n",
        "os.chdir('GenerationEval')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gJR_6pLm65L",
        "outputId": "043713e2-4b92-4020-e766-be78db9a7efb"
      },
      "source": [
        "!git checkout humaneval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Branch 'humaneval' set up to track remote branch 'humaneval' from 'origin'.\n",
            "Switched to a new branch 'humaneval'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGtosNWZm7NZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552348ed-a381-4e41-98dd-6a87c1f513c3"
      },
      "source": [
        "import copy\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from statsmodels.stats.inter_rater import fleiss_kappa\n",
        "from scipy.stats import ranksums\n",
        "\n",
        "SYSTEMS_PATH = 'data/human_evaluation/ru_clean/'\n",
        "REFERENCES_PATH = 'data/human_evaluation/data_REF.json'\n",
        "DOMAIN_PATH = 'data/human_evaluation/ref2domain.json'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkonoswLnGh1"
      },
      "source": [
        "# Parsing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4aKdB4KnCau"
      },
      "source": [
        "rdfs = json.load(open(REFERENCES_PATH))\n",
        "sys_files = [w for w in os.listdir(SYSTEMS_PATH) if not w.startswith('.')]\n",
        "domains = json.load(open(DOMAIN_PATH))\n",
        "\n",
        "doc_id = 1\n",
        "data = []\n",
        "for sys_file in sys_files:\n",
        "    results = json.load(open(os.path.join(SYSTEMS_PATH, sys_file)))\n",
        "    submission_id = sys_file.replace('.json', '').replace('human_eval_id_', '')\n",
        "\n",
        "    for sample_id in results:\n",
        "        entry = [w for w in rdfs['entries'] if list(w.keys())[0] == sample_id][0]\n",
        "        for worker_id in results[sample_id]:\n",
        "            assign = results[sample_id][worker_id]\n",
        "            inp = {\n",
        "                'id': doc_id,\n",
        "                'sample_id': sample_id,\n",
        "                'submission_id': submission_id,\n",
        "                'worker_id': worker_id,\n",
        "                'category': entry[sample_id]['category'],\n",
        "                'size': entry[sample_id]['size'],\n",
        "            }\n",
        "            inp.update(assign)\n",
        "            data.append(inp)\n",
        "            doc_id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b21OudIinORN"
      },
      "source": [
        "# Inter-rater Agreement\n",
        "## Fleiss' Kappa\n",
        "\n",
        "Discretize the ratings in 5 categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Joq3COs3nJIa"
      },
      "source": [
        "n_cat, max_range = 5, 100 # number of categories\n",
        "data_discretized = []\n",
        "\n",
        "ids = [w['id'] for w in data]\n",
        "correctness = [int((n_cat* w['Correctness']) / (max_range+1)) for w in data]\n",
        "coverage = [int((n_cat* w['DataCoverage']) / (max_range+1)) for w in data]\n",
        "fluency = [int((n_cat* w['Fluency']) / (max_range+1)) for w in data]\n",
        "relevance = [int((n_cat* w['Relevance']) / (max_range+1)) for w in data]\n",
        "structure = [int((n_cat* w['TextStructure']) / (max_range+1)) for w in data]\n",
        "    \n",
        "for i, id_ in enumerate(ids):\n",
        "    for j, row in enumerate(data):\n",
        "        if row['id'] == id_:\n",
        "            row_ = copy.copy(row)\n",
        "            row_['Correctness'] = correctness[i]\n",
        "            row_['DataCoverage'] = coverage[i]\n",
        "            row_['Fluency'] = fluency[i]\n",
        "            row_['Relevance'] = relevance[i]\n",
        "            row_['TextStructure'] = structure[i]\n",
        "            data_discretized.append(row_)\n",
        "            break\n",
        "\n",
        "data_discretized = sorted(data_discretized, key=lambda x: x['id'])         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3l96S0BnTgc"
      },
      "source": [
        "Computing the Fleiss' Kappa agreements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HJbiN24-nQaJ",
        "outputId": "8b5d466e-23ff-412b-8304-1f944fa4f618"
      },
      "source": [
        "assignments = set([(w['submission_id'], w['sample_id']) for w in data_discretized])\n",
        "\n",
        "correctness = np.zeros((len(assignments), n_cat))\n",
        "coverage = np.zeros((len(assignments), n_cat))\n",
        "fluency = np.zeros((len(assignments), n_cat))\n",
        "relevance = np.zeros((len(assignments), n_cat))\n",
        "structure = np.zeros((len(assignments), n_cat))\n",
        "\n",
        "for i, (submission_id, sample_id) in enumerate(assignments):\n",
        "    fdata = [w for w in data_discretized if w['submission_id'] == submission_id and w['sample_id'] == sample_id]\n",
        "    \n",
        "    for rating in fdata:\n",
        "        correctness[i, rating['Correctness']-1] += 1\n",
        "        coverage[i, rating['DataCoverage']-1] += 1\n",
        "        fluency[i, rating['Fluency']-1] += 1\n",
        "        relevance[i, rating['Relevance']-1] += 1\n",
        "        structure[i, rating['TextStructure']-1] += 1      \n",
        "        \n",
        "pd.DataFrame({\"Fleiss' Kappa\": {\n",
        "    'Correctness': fleiss_kappa(correctness),\n",
        "    'Data Coverage': fleiss_kappa(coverage),\n",
        "    'Fluency': fleiss_kappa(fluency),\n",
        "    'Relevance': fleiss_kappa(relevance),\n",
        "    'Text Structure': fleiss_kappa(structure),\n",
        "}}).round(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fleiss' Kappa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Correctness</th>\n",
              "      <td>0.244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data Coverage</th>\n",
              "      <td>0.435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fluency</th>\n",
              "      <td>0.156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Relevance</th>\n",
              "      <td>0.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Text Structure</th>\n",
              "      <td>0.132</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Fleiss' Kappa\n",
              "Correctness             0.244\n",
              "Data Coverage           0.435\n",
              "Fluency                 0.156\n",
              "Relevance               0.125\n",
              "Text Structure          0.132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw8ORC8RnafX"
      },
      "source": [
        "# Human Evaluation\n",
        "\n",
        "Results of the human evaluation for the participating systems according to original ratings of correctness, data coverage, fluency, relevance and text structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "mN38HX8TnVU0",
        "outputId": "393e6f13-b5cb-42b2-9b83-26685681570a"
      },
      "source": [
        "df = pd.DataFrame(data)\n",
        "\n",
        "submissions = df.groupby(\"submission_id\")[\"Correctness\", \"DataCoverage\", \"Fluency\", \"Relevance\", \"TextStructure\"]\n",
        "submissions.agg([np.mean, np.std]).sort_values(by=('Correctness', 'mean'), ascending=False).round(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Correctness</th>\n",
              "      <th colspan=\"2\" halign=\"left\">DataCoverage</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Fluency</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Relevance</th>\n",
              "      <th colspan=\"2\" halign=\"left\">TextStructure</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>submission_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bt5</th>\n",
              "      <td>95.594</td>\n",
              "      <td>11.577</td>\n",
              "      <td>95.630</td>\n",
              "      <td>9.961</td>\n",
              "      <td>93.088</td>\n",
              "      <td>14.143</td>\n",
              "      <td>95.385</td>\n",
              "      <td>11.676</td>\n",
              "      <td>95.745</td>\n",
              "      <td>11.601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FBConvAI</th>\n",
              "      <td>90.779</td>\n",
              "      <td>17.901</td>\n",
              "      <td>92.339</td>\n",
              "      <td>17.709</td>\n",
              "      <td>90.248</td>\n",
              "      <td>17.853</td>\n",
              "      <td>93.491</td>\n",
              "      <td>17.440</td>\n",
              "      <td>93.764</td>\n",
              "      <td>14.286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rus_REF</th>\n",
              "      <td>90.630</td>\n",
              "      <td>18.217</td>\n",
              "      <td>94.000</td>\n",
              "      <td>14.474</td>\n",
              "      <td>89.021</td>\n",
              "      <td>20.070</td>\n",
              "      <td>93.636</td>\n",
              "      <td>14.852</td>\n",
              "      <td>92.082</td>\n",
              "      <td>17.564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cuni_ufal</th>\n",
              "      <td>90.382</td>\n",
              "      <td>20.700</td>\n",
              "      <td>93.155</td>\n",
              "      <td>16.980</td>\n",
              "      <td>92.921</td>\n",
              "      <td>13.779</td>\n",
              "      <td>93.306</td>\n",
              "      <td>17.177</td>\n",
              "      <td>96.073</td>\n",
              "      <td>11.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pavel_med</th>\n",
              "      <td>88.585</td>\n",
              "      <td>21.181</td>\n",
              "      <td>82.230</td>\n",
              "      <td>21.431</td>\n",
              "      <td>88.252</td>\n",
              "      <td>21.491</td>\n",
              "      <td>92.224</td>\n",
              "      <td>16.161</td>\n",
              "      <td>91.309</td>\n",
              "      <td>18.479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Huawei</th>\n",
              "      <td>87.033</td>\n",
              "      <td>23.697</td>\n",
              "      <td>86.448</td>\n",
              "      <td>21.397</td>\n",
              "      <td>85.679</td>\n",
              "      <td>23.897</td>\n",
              "      <td>91.761</td>\n",
              "      <td>19.421</td>\n",
              "      <td>89.515</td>\n",
              "      <td>21.019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OSU_Neural_NLG</th>\n",
              "      <td>84.830</td>\n",
              "      <td>25.781</td>\n",
              "      <td>82.836</td>\n",
              "      <td>23.884</td>\n",
              "      <td>88.558</td>\n",
              "      <td>21.273</td>\n",
              "      <td>90.433</td>\n",
              "      <td>20.299</td>\n",
              "      <td>92.958</td>\n",
              "      <td>17.266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BASELINE</th>\n",
              "      <td>80.830</td>\n",
              "      <td>25.715</td>\n",
              "      <td>93.191</td>\n",
              "      <td>17.387</td>\n",
              "      <td>84.691</td>\n",
              "      <td>21.115</td>\n",
              "      <td>91.294</td>\n",
              "      <td>19.648</td>\n",
              "      <td>87.645</td>\n",
              "      <td>21.338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Correctness         DataCoverage  ... Relevance TextStructure        \n",
              "                      mean     std         mean  ...       std          mean     std\n",
              "submission_id                                    ...                                \n",
              "bt5                 95.594  11.577       95.630  ...    11.676        95.745  11.601\n",
              "FBConvAI            90.779  17.901       92.339  ...    17.440        93.764  14.286\n",
              "rus_REF             90.630  18.217       94.000  ...    14.852        92.082  17.564\n",
              "cuni_ufal           90.382  20.700       93.155  ...    17.177        96.073  11.017\n",
              "pavel_med           88.585  21.181       82.230  ...    16.161        91.309  18.479\n",
              "Huawei              87.033  23.697       86.448  ...    19.421        89.515  21.019\n",
              "OSU_Neural_NLG      84.830  25.781       82.836  ...    20.299        92.958  17.266\n",
              "BASELINE            80.830  25.715       93.191  ...    19.648        87.645  21.338\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o2sM3a1ne90"
      },
      "source": [
        "# Human Evaluation (Z-Scores)\n",
        "\n",
        "Results of the human evaluation for the participating systems according to normalized z-scores for correctness, data coverage, fluency, relevance and text structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "pPcXSN30nc7c",
        "outputId": "13f92cec-d00f-4a49-998b-7d8eaa49950e"
      },
      "source": [
        "normdata = []\n",
        "worker_ids = set([w['worker_id'] for w in data])\n",
        "for worker_id in worker_ids:\n",
        "    fdata = [w for w in data if w['worker_id'] == worker_id]\n",
        "    \n",
        "    ids = [w['id'] for w in fdata]\n",
        "    correctness = zscore([w['Correctness'] for w in fdata])\n",
        "    coverage = zscore([w['DataCoverage'] for w in fdata])\n",
        "    fluency = zscore([w['Fluency'] for w in fdata])\n",
        "    relevance = zscore([w['Relevance'] for w in fdata])\n",
        "    structure = zscore([w['TextStructure'] for w in fdata])\n",
        "    \n",
        "    for i, id_ in enumerate(ids):\n",
        "        for j, row in enumerate(data):\n",
        "            if row['id'] == id_:\n",
        "                row_ = copy.copy(row)\n",
        "                row_['Correctness'] = correctness[i]\n",
        "                row_['DataCoverage'] = coverage[i]\n",
        "                row_['Fluency'] = fluency[i]\n",
        "                row_['Relevance'] = relevance[i]\n",
        "                row_['TextStructure'] = structure[i]\n",
        "                normdata.append(row_)\n",
        "                break\n",
        "                \n",
        "df = pd.DataFrame(normdata)\n",
        "\n",
        "submissions = df.groupby(\"submission_id\")[\"Correctness\", \"DataCoverage\", \"Fluency\", \"Relevance\", \"TextStructure\"]\n",
        "submissions.agg([np.mean, np.std]).sort_values(by=('Correctness', 'mean'), ascending=False).round(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:2419: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return (a - mns) / sstd\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Correctness</th>\n",
              "      <th colspan=\"2\" halign=\"left\">DataCoverage</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Fluency</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Relevance</th>\n",
              "      <th colspan=\"2\" halign=\"left\">TextStructure</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>submission_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bt5</th>\n",
              "      <td>0.340</td>\n",
              "      <td>0.586</td>\n",
              "      <td>0.312</td>\n",
              "      <td>0.534</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.613</td>\n",
              "      <td>0.174</td>\n",
              "      <td>0.696</td>\n",
              "      <td>0.219</td>\n",
              "      <td>0.658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rus_REF</th>\n",
              "      <td>0.109</td>\n",
              "      <td>0.794</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.707</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.960</td>\n",
              "      <td>0.065</td>\n",
              "      <td>0.814</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>0.969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cuni_ufal</th>\n",
              "      <td>0.101</td>\n",
              "      <td>0.951</td>\n",
              "      <td>0.204</td>\n",
              "      <td>0.763</td>\n",
              "      <td>0.213</td>\n",
              "      <td>0.691</td>\n",
              "      <td>0.077</td>\n",
              "      <td>0.891</td>\n",
              "      <td>0.218</td>\n",
              "      <td>0.690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FBConvAI</th>\n",
              "      <td>0.080</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.133</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.837</td>\n",
              "      <td>0.027</td>\n",
              "      <td>0.967</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pavel_med</th>\n",
              "      <td>0.021</td>\n",
              "      <td>1.009</td>\n",
              "      <td>-0.470</td>\n",
              "      <td>1.202</td>\n",
              "      <td>-0.060</td>\n",
              "      <td>1.221</td>\n",
              "      <td>-0.022</td>\n",
              "      <td>1.001</td>\n",
              "      <td>-0.077</td>\n",
              "      <td>1.195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Huawei</th>\n",
              "      <td>-0.084</td>\n",
              "      <td>1.111</td>\n",
              "      <td>-0.189</td>\n",
              "      <td>1.114</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>1.198</td>\n",
              "      <td>-0.060</td>\n",
              "      <td>1.110</td>\n",
              "      <td>-0.183</td>\n",
              "      <td>1.211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OSU_Neural_NLG</th>\n",
              "      <td>-0.181</td>\n",
              "      <td>1.179</td>\n",
              "      <td>-0.422</td>\n",
              "      <td>1.325</td>\n",
              "      <td>-0.050</td>\n",
              "      <td>1.104</td>\n",
              "      <td>-0.182</td>\n",
              "      <td>1.242</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BASELINE</th>\n",
              "      <td>-0.387</td>\n",
              "      <td>1.213</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.870</td>\n",
              "      <td>-0.247</td>\n",
              "      <td>1.098</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>1.134</td>\n",
              "      <td>-0.270</td>\n",
              "      <td>1.192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Correctness        DataCoverage  ... Relevance TextStructure       \n",
              "                      mean    std         mean  ...       std          mean    std\n",
              "submission_id                                   ...                               \n",
              "bt5                  0.340  0.586        0.312  ...     0.696         0.219  0.658\n",
              "rus_REF              0.109  0.794        0.230  ...     0.814        -0.005  0.969\n",
              "cuni_ufal            0.101  0.951        0.204  ...     0.891         0.218  0.690\n",
              "FBConvAI             0.080  0.833        0.133  ...     0.967         0.079  0.808\n",
              "pavel_med            0.021  1.009       -0.470  ...     1.001        -0.077  1.195\n",
              "Huawei              -0.084  1.111       -0.189  ...     1.110        -0.183  1.211\n",
              "OSU_Neural_NLG      -0.181  1.179       -0.422  ...     1.242         0.019  0.998\n",
              "BASELINE            -0.387  1.213        0.200  ...     1.134        -0.270  1.192\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH-aSFE0nJUf"
      },
      "source": [
        "import json\n",
        "submission_ids = sorted(list(set([w['submission_id'] for w in normdata])))\n",
        "sample_ids = sorted(list(set([w['sample_id'] for w in normdata])), key=lambda x: int(x))\n",
        "\n",
        "finaldata = []\n",
        "for submission_id in submission_ids:\n",
        "  for sample_id in sample_ids:\n",
        "    fdata = [w for w in normdata if w['submission_id'] == submission_id and w['sample_id'] == sample_id]\n",
        "\n",
        "    if len(fdata) > 0:\n",
        "      finaldata.append({\n",
        "        'submission_id': submission_id,\n",
        "        'size': fdata[0]['size'],\n",
        "        'sample_id': sample_id,\n",
        "        'category': fdata[0]['category'],\n",
        "        'Correctness': np.nan_to_num(np.mean(np.nan_to_num([w['Correctness'] for w in fdata]))),\n",
        "        'DataCoverage': np.nan_to_num(np.mean(np.nan_to_num([w['DataCoverage'] for w in fdata]))),\n",
        "        'Fluency': np.nan_to_num(np.mean(np.nan_to_num([w['Fluency'] for w in fdata]))),\n",
        "        'Relevance': np.nan_to_num(np.mean(np.nan_to_num([w['Relevance'] for w in fdata]))),\n",
        "        'TextStructure': np.nan_to_num(np.mean(np.nan_to_num([w['TextStructure'] for w in fdata])))\n",
        "      })\n",
        "\n",
        "json.dump(finaldata, open('russian_data.json', 'w'), separators=(',', ':'), indent=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "160-jVRNnkHU"
      },
      "source": [
        "# Statistical Testing\n",
        "\n",
        "## Wilcoxon rank-sum significant test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAdU6ffQnhFo"
      },
      "source": [
        "def parse(data, normdata):\n",
        "    correctness, coverage, fluency, relevance, structure = {}, {}, {}, {}, {}\n",
        "    normcorrectness, normcoverage, normfluency, normrelevance, normstructure = {}, {}, {}, {}, {}\n",
        "\n",
        "    submission_ids = sorted(list(set([w['submission_id'] for w in data])))\n",
        "    sample_ids = sorted(list(set([w['sample_id'] for w in data])), key=lambda x: int(x))\n",
        "    for i, submission_id in enumerate(submission_ids):\n",
        "        if submission_id not in correctness:\n",
        "            correctness[submission_id] = []\n",
        "            coverage[submission_id] = []\n",
        "            fluency[submission_id] = []\n",
        "            relevance[submission_id] = []\n",
        "            structure[submission_id] = []\n",
        "\n",
        "            normcorrectness[submission_id] = []\n",
        "            normcoverage[submission_id] = []\n",
        "            normfluency[submission_id] = []\n",
        "            normrelevance[submission_id] = []\n",
        "            normstructure[submission_id] = []\n",
        "        \n",
        "        for sample_id in sample_ids:\n",
        "          fdata = [w for w in data if w['submission_id'] == submission_id and w['sample_id'] == sample_id]\n",
        "          fnormdata = [w for w in normdata if w['submission_id'] == submission_id and w['sample_id'] == sample_id]\n",
        "\n",
        "          correctness[submission_id].append(np.mean([w['Correctness'] for w in fdata]))\n",
        "          coverage[submission_id].append(np.mean([w['DataCoverage'] for w in fdata]))\n",
        "          fluency[submission_id].append(np.mean([w['Fluency'] for w in fdata]))\n",
        "          relevance[submission_id].append(np.mean([w['Relevance'] for w in fdata]))\n",
        "          structure[submission_id].append(np.mean([w['TextStructure'] for w in fdata]))\n",
        "\n",
        "          # Average the z-scores (setting nans to zeros) of the three turkers for each trial of each system\n",
        "          normcorrectness[submission_id].append(np.mean(np.nan_to_num([w['Correctness'] for w in fnormdata])))\n",
        "          normcoverage[submission_id].append(np.mean(np.nan_to_num([w['DataCoverage'] for w in fnormdata])))\n",
        "          normfluency[submission_id].append(np.mean(np.nan_to_num([w['Fluency'] for w in fnormdata])))\n",
        "          normrelevance[submission_id].append(np.mean(np.nan_to_num([w['Relevance'] for w in fnormdata])))\n",
        "          normstructure[submission_id].append(np.mean(np.nan_to_num([w['TextStructure'] for w in fnormdata])))\n",
        "    return correctness, coverage, fluency, relevance, structure, \\\n",
        "            normcorrectness, normcoverage, normfluency, normrelevance, normstructure\n",
        "    \n",
        "def rank_systems(X, raw_X, name):\n",
        "    submissions = sorted(X.keys(), key=lambda x: np.mean(X[x]), reverse=True)\n",
        "    ranking = { s:1 for i, s in enumerate(submissions) }\n",
        "\n",
        "    for i, subA in enumerate(submissions):\n",
        "        for j, subB in enumerate(submissions[i+1:]):\n",
        "            s, pvalue = ranksums(X[subA], X[subB])\n",
        "            if pvalue < 0.05:\n",
        "                ranking[subB] = ranking[subA] + 1\n",
        "            elif ranking[subB] < ranking[submissions[i+1+j-1]] :\n",
        "                ranking[subB] = ranking[submissions[i+1+j-1]] \n",
        "\n",
        "    ranking_ = {}\n",
        "    for sub in ranking:\n",
        "        rank = ranking[sub]\n",
        "        normmean = np.mean(X[sub])\n",
        "        mean = np.mean(raw_X[sub])\n",
        "        ranking_[sub] = { 'Ranking': int(rank), name + ' (Z.)': round(normmean, 3), name: round(mean, 3) }\n",
        "\n",
        "    return ranking_\n",
        "\n",
        "correctness, coverage, fluency, relevance, structure, \\\n",
        "      normcorrectness, normcoverage, normfluency, normrelevance, normstructure = parse(data, normdata)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_U7imwKnrzK"
      },
      "source": [
        "### All Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "NZ6_9w1Zno3l",
        "outputId": "87168808-097a-4c35-e0b9-584b43d7c415"
      },
      "source": [
        "pd.DataFrame(rank_systems(normcorrectness, correctness, 'Correctness')).T.sort_index(axis=0, key=lambda x: x.str.lower())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ranking</th>\n",
              "      <th>Correctness (Z.)</th>\n",
              "      <th>Correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BASELINE</th>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.387</td>\n",
              "      <td>80.830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bt5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.340</td>\n",
              "      <td>95.594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cuni_ufal</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.101</td>\n",
              "      <td>90.382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FBConvAI</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.080</td>\n",
              "      <td>90.779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Huawei</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.084</td>\n",
              "      <td>87.033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OSU_Neural_NLG</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.181</td>\n",
              "      <td>84.830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pavel_med</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.021</td>\n",
              "      <td>88.585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rus_REF</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.109</td>\n",
              "      <td>90.630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Ranking  Correctness (Z.)  Correctness\n",
              "BASELINE            4.0            -0.387       80.830\n",
              "bt5                 1.0             0.340       95.594\n",
              "cuni_ufal           2.0             0.101       90.382\n",
              "FBConvAI            2.0             0.080       90.779\n",
              "Huawei              2.0            -0.084       87.033\n",
              "OSU_Neural_NLG      3.0            -0.181       84.830\n",
              "pavel_med           2.0             0.021       88.585\n",
              "rus_REF             2.0             0.109       90.630"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmJx722tb6yR"
      },
      "source": [
        "def format_column(column):\n",
        "  return [str(val).replace(',', '.') for val in column]\n",
        "\n",
        "correctness_all = pd.DataFrame(rank_systems(normcorrectness, correctness, 'Correctness')).T.sort_index(axis=0, key=lambda x: x.str.lower())\n",
        "correctness_all[['Ranking', 'Correctness', 'Correctness (Z.)']] = correctness_all[['Ranking', 'Correctness', 'Correctness (Z.)']].apply(format_column)\n",
        "correctness_all.to_excel('./correctness_all.xlsx', header=False, index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "5Dwu8595nqYC",
        "outputId": "ade2c328-5e38-4d7a-9558-66f7f2ff2110"
      },
      "source": [
        "pd.DataFrame(rank_systems(normcoverage, coverage, 'Coverage')).T.sort_index(axis=0, key=lambda x: x.str.lower())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ranking</th>\n",
              "      <th>Coverage (Z.)</th>\n",
              "      <th>Coverage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BASELINE</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.200</td>\n",
              "      <td>93.191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bt5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.312</td>\n",
              "      <td>95.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cuni_ufal</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.203</td>\n",
              "      <td>93.155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FBConvAI</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.133</td>\n",
              "      <td>92.339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Huawei</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.189</td>\n",
              "      <td>86.448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OSU_Neural_NLG</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.422</td>\n",
              "      <td>82.836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pavel_med</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.467</td>\n",
              "      <td>82.230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rus_REF</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.230</td>\n",
              "      <td>94.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Ranking  Coverage (Z.)  Coverage\n",
              "BASELINE            1.0          0.200    93.191\n",
              "bt5                 1.0          0.312    95.630\n",
              "cuni_ufal           1.0          0.203    93.155\n",
              "FBConvAI            1.0          0.133    92.339\n",
              "Huawei              2.0         -0.189    86.448\n",
              "OSU_Neural_NLG      2.0         -0.422    82.836\n",
              "pavel_med           3.0         -0.467    82.230\n",
              "rus_REF             1.0          0.230    94.000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YWAGrcrcN_E"
      },
      "source": [
        "coverage_all = pd.DataFrame(rank_systems(normcoverage, coverage, 'Coverage')).T.sort_index(axis=0, key=lambda x: x.str.lower())\n",
        "coverage_all[['Ranking', 'Coverage', 'Coverage (Z.)']] = coverage_all[['Ranking', 'Coverage', 'Coverage (Z.)']].apply(format_column)\n",
        "coverage_all.to_excel('./coverage_all.xlsx', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "LWTa6Ub8nwhp",
        "outputId": "271e9b6e-8c5d-466e-a2a4-e9eb94a04195"
      },
      "source": [
        "pd.DataFrame(rank_systems(normfluency, fluency, 'Fluency')).T.sort_index(axis=0, key=lambda x: x.str.lower())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ranking</th>\n",
              "      <th>Fluency (Z.)</th>\n",
              "      <th>Fluency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BASELINE</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.247</td>\n",
              "      <td>84.691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bt5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>93.088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cuni_ufal</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.213</td>\n",
              "      <td>92.921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FBConvAI</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.063</td>\n",
              "      <td>90.248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Huawei</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>85.679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OSU_Neural_NLG</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.050</td>\n",
              "      <td>88.558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pavel_med</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.060</td>\n",
              "      <td>88.252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rus_REF</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.022</td>\n",
              "      <td>89.021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Ranking  Fluency (Z.)  Fluency\n",
              "BASELINE            3.0        -0.247   84.691\n",
              "bt5                 1.0         0.232   93.088\n",
              "cuni_ufal           1.0         0.213   92.921\n",
              "FBConvAI            2.0         0.063   90.248\n",
              "Huawei              3.0        -0.174   85.679\n",
              "OSU_Neural_NLG      2.0        -0.050   88.558\n",
              "pavel_med           2.0        -0.060   88.252\n",
              "rus_REF             2.0         0.022   89.021"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA8gvVekceLy"
      },
      "source": [
        "fluency_all = pd.DataFrame(rank_systems(normfluency, fluency, 'Fluency')).T.sort_index(axis=0, key=lambda x: x.str.lower())\n",
        "fluency_all[['Ranking', 'Fluency', 'Fluency (Z.)']] = fluency_all[['Ranking', 'Fluency', 'Fluency (Z.)']].apply(format_column)\n",
        "fluency_all.to_excel('./fluency_all.xlsx', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Qot2CPvanwlW",
        "outputId": "b8dff9eb-d4f3-4de4-a453-f566d535cb00"
      },
      "source": [
        "pd.DataFrame(rank_systems(normrelevance, relevance, 'Relevance')).T.sort_index(axis=0, key=lambda x: x.str.lower())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ranking</th>\n",
              "      <th>Relevance (Z.)</th>\n",
              "      <th>Relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BASELINE</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>91.294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bt5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.174</td>\n",
              "      <td>95.385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cuni_ufal</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.077</td>\n",
              "      <td>93.306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FBConvAI</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.027</td>\n",
              "      <td>93.491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Huawei</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.060</td>\n",
              "      <td>91.761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OSU_Neural_NLG</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.182</td>\n",
              "      <td>90.433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pavel_med</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.022</td>\n",
              "      <td>92.224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rus_REF</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.065</td>\n",
              "      <td>93.636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Ranking  Relevance (Z.)  Relevance\n",
              "BASELINE            2.0          -0.079     91.294\n",
              "bt5                 1.0           0.174     95.385\n",
              "cuni_ufal           1.0           0.077     93.306\n",
              "FBConvAI            2.0           0.027     93.491\n",
              "Huawei              2.0          -0.060     91.761\n",
              "OSU_Neural_NLG      2.0          -0.182     90.433\n",
              "pavel_med           2.0          -0.022     92.224\n",
              "rus_REF             2.0           0.065     93.636"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh27MkFScrH2"
      },
      "source": [
        "relevance_all = pd.DataFrame(rank_systems(normrelevance, relevance, 'Relevance')).T.sort_index(axis=0, key=lambda x: x.str.lower())\n",
        "relevance_all[['Ranking', 'Relevance', 'Relevance (Z.)']] = relevance_all[['Ranking', 'Relevance', 'Relevance (Z.)']].apply(format_column)\n",
        "relevance_all.to_excel('./relevance_all.xlsx', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "n56UvUUOnwn3",
        "outputId": "d7a1e173-d14e-42d0-8e75-3998150330b4"
      },
      "source": [
        "pd.DataFrame(rank_systems(normstructure, structure, 'Text Structure')).T.sort_index(axis=0, key=lambda x: x.str.lower())\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ranking</th>\n",
              "      <th>Text Structure (Z.)</th>\n",
              "      <th>Text Structure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BASELINE</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.270</td>\n",
              "      <td>87.645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bt5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.219</td>\n",
              "      <td>95.745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cuni_ufal</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.218</td>\n",
              "      <td>96.073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FBConvAI</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.079</td>\n",
              "      <td>93.764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Huawei</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.183</td>\n",
              "      <td>89.515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OSU_Neural_NLG</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.019</td>\n",
              "      <td>92.958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pavel_med</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.077</td>\n",
              "      <td>91.309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rus_REF</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>92.082</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Ranking  Text Structure (Z.)  Text Structure\n",
              "BASELINE            3.0               -0.270          87.645\n",
              "bt5                 1.0                0.219          95.745\n",
              "cuni_ufal           1.0                0.218          96.073\n",
              "FBConvAI            2.0                0.079          93.764\n",
              "Huawei              3.0               -0.183          89.515\n",
              "OSU_Neural_NLG      2.0                0.019          92.958\n",
              "pavel_med           2.0               -0.077          91.309\n",
              "rus_REF             2.0               -0.005          92.082"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BFDeXL3c30z"
      },
      "source": [
        "structure_all = pd.DataFrame(rank_systems(normstructure, structure, 'Text Structure')).T.sort_index(axis=0, key=lambda x: x.str.lower())\n",
        "structure_all[['Ranking', 'Text Structure (Z.)', 'Text Structure']] = structure_all[['Ranking', 'Text Structure (Z.)', 'Text Structure']].apply(format_column)\n",
        "structure_all.to_excel('./structure_all.xlsx', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RImgm6XLc4gO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}